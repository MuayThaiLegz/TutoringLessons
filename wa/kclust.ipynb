{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183504 entries, 0 to 183503\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   Unnamed: 0     183504 non-null  object        \n",
      " 1   Date           183504 non-null  datetime64[ns]\n",
      " 2   Time           183504 non-null  object        \n",
      " 3   Ticker         183504 non-null  object        \n",
      " 4   Expiration     183504 non-null  datetime64[ns]\n",
      " 5   Strike         183504 non-null  float64       \n",
      " 6   C/P            183504 non-null  object        \n",
      " 7   Spot           183504 non-null  float64       \n",
      " 8   Details        183504 non-null  object        \n",
      " 9   Type           183504 non-null  object        \n",
      " 10  Prem           183504 non-null  float64       \n",
      " 11  Sentiment      183504 non-null  object        \n",
      " 12  Execution      183504 non-null  object        \n",
      " 13  Open Interest  183504 non-null  int64         \n",
      " 14  Volume         183504 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(3), int64(2), object(8)\n",
      "memory usage: 21.0+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JBarr\\AppData\\Local\\Temp\\ipykernel_35824\\3573196668.py:43: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  moneyFlow['Spot'] = moneyFlow['Spot'].str.replace(\"$\", \"\")\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Mar 20 06:20:43 2023\n",
    "\n",
    "@author: abdullahalbinsaleh\n",
    "\n",
    "This version uses normal random data splitting technique \n",
    "\"\"\"\n",
    "\n",
    "#-------------------------import librarires-------------------------#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "#-------------------------Load dataset-------------------------#\n",
    "moneyFlow = pd.read_excel(\"moneyFlow.xlsx\")\n",
    "\n",
    "#-------------------------Data Exploration-------------------------#\n",
    "moneyFlow.head()\n",
    "moneyFlow.info()\n",
    "moneyFlow.columns\n",
    "\n",
    "\n",
    "#-------------------------Data Preparation & Pre-Processing-------------------------#\n",
    "#Drop missing values \n",
    "moneyFlow.dropna(inplace=True)\n",
    "moneyFlow = moneyFlow.drop('Unnamed: 0', axis=1)\n",
    "#drop $ sign from Spot feature \n",
    "# convert the 'Spot' column to a string\n",
    "moneyFlow['Spot'] = moneyFlow['Spot'].astype(str)\n",
    "moneyFlow['Spot'] = moneyFlow['Spot'].str.replace(\"$\", \"\")\n",
    "# convert the 'Spot' column back to float\n",
    "moneyFlow['Spot'] = moneyFlow['Spot'].astype(float)\n",
    "\n",
    "#convert Date and Expiration to timestamp \n",
    "moneyFlow[\"Date\"] = pd.to_datetime(moneyFlow[\"Date\"])\n",
    "moneyFlow[\"Expiration\"] = pd.to_datetime(moneyFlow[\"Expiration\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183504 entries, 0 to 183503\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   Strike                 183504 non-null  float64\n",
      " 1   Spot                   183504 non-null  float64\n",
      " 2   Prem                   183504 non-null  float64\n",
      " 3   Sentiment              183504 non-null  object \n",
      " 4   Duration               183504 non-null  int64  \n",
      " 5   Type_SWEEP             183504 non-null  uint8  \n",
      " 6   Type_TRADE             183504 non-null  uint8  \n",
      " 7   Execution_ABOVE ASK    183504 non-null  uint8  \n",
      " 8   Execution_AT ASK       183504 non-null  uint8  \n",
      " 9   Execution_AT BID       183504 non-null  uint8  \n",
      " 10  Execution_AT MIDPOINT  183504 non-null  uint8  \n",
      " 11  Execution_BELOW BID    183504 non-null  uint8  \n",
      " 12  C/P_CALL               183504 non-null  uint8  \n",
      " 13  C/P_PUT                183504 non-null  uint8  \n",
      "dtypes: float64(3), int64(1), object(1), uint8(9)\n",
      "memory usage: 8.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Strike', 'Spot', 'Prem', 'Sentiment', 'Duration', 'Type_SWEEP',\n",
       "       'Type_TRADE', 'Execution_ABOVE ASK', 'Execution_AT ASK',\n",
       "       'Execution_AT BID', 'Execution_AT MIDPOINT', 'Execution_BELOW BID',\n",
       "       'C/P_CALL', 'C/P_PUT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#-------------------------Feature Engineering -------------------------#\n",
    "#Split Details feature into two features \n",
    "moneyFlow[[\"Size\", \"Price\"]] = moneyFlow[\"Details\"].str.split(\"@\", expand=True)\n",
    "#drop the Details feature \n",
    "moneyFlow.drop(columns=[\"Details\"], inplace=True)\n",
    "\n",
    "#Find options duration in days \n",
    "moneyFlow[\"Duration\"] = (moneyFlow[\"Expiration\"]-moneyFlow[\"Date\"]).dt.days\n",
    "#drop the Date and Expiration deatuers \n",
    "moneyFlow.drop(columns=[\"Date\"], inplace=True)\n",
    "moneyFlow.drop(columns=[\"Expiration\"], inplace=True)\n",
    "\n",
    "\n",
    "#Convert categoircal variables into dummy variables \n",
    "moneyFlow = pd.get_dummies(moneyFlow, columns=[\"Type\", \"Execution\", \"C/P\"])\n",
    "\n",
    "\n",
    "#-------------------------Feature Selection Using Domain Knowledge -------------------------#\n",
    "#Drop useless predictors using domain knowledge\n",
    "moneyFlow.drop(columns=[\"Time\", \"Ticker\", \"Price\", \"Size\", \"Volume\", \"Open Interest\"], inplace=True)\n",
    "\n",
    "#new data set columns \n",
    "moneyFlow.info()\n",
    "moneyFlow.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-------------------------Cluestring-------------------------#\n",
    "\n",
    "\n",
    "#clustering based  on Premium and Type of Trade\n",
    "premType = moneyFlow.iloc[:,[2,5,6]]\n",
    "\n",
    "#scale the data\n",
    "scaler = StandardScaler()\n",
    "premType_scaled = scaler.fit_transform(premType)\n",
    "premType_scaled = pd.DataFrame(premType_scaled, columns=premType.columns, index= premType.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmodel = KMeans()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: threadpoolctl in c:\\users\\jbarr\\anaconda3\\envs\\myenv\\lib\\site-packages (2.2.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting threadpoolctl\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 2.2.0\n",
      "    Uninstalling threadpoolctl-2.2.0:\n",
      "      Successfully uninstalled threadpoolctl-2.2.0\n",
      "Successfully installed threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade threadpoolctl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#2 clusters \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m premType_2_Clusters \u001b[39m=\u001b[39m KMeans(n_clusters\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(premType_scaled)\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1468\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1465\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInitialization complete\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1467\u001b[0m \u001b[39m# run a k-means once\u001b[39;00m\n\u001b[1;32m-> 1468\u001b[0m labels, inertia, centers, n_iter_ \u001b[39m=\u001b[39m kmeans_single(\n\u001b[0;32m   1469\u001b[0m     X,\n\u001b[0;32m   1470\u001b[0m     sample_weight,\n\u001b[0;32m   1471\u001b[0m     centers_init,\n\u001b[0;32m   1472\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m   1473\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1474\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tol,\n\u001b[0;32m   1475\u001b[0m     n_threads\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_threads,\n\u001b[0;32m   1476\u001b[0m )\n\u001b[0;32m   1478\u001b[0m \u001b[39m# determine if these results are the best so far\u001b[39;00m\n\u001b[0;32m   1479\u001b[0m \u001b[39m# we chose a new run if it has a better inertia and the clustering is\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \u001b[39m# different from the best so far (it's possible that the inertia is\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m \u001b[39m# slightly better even if the clustering is the same with potentially\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \u001b[39m# permuted labels, due to rounding errors)\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m \u001b[39mif\u001b[39;00m best_inertia \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   1484\u001b[0m     inertia \u001b[39m<\u001b[39m best_inertia\n\u001b[0;32m   1485\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_same_clustering(labels, best_labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_clusters)\n\u001b[0;32m   1486\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:679\u001b[0m, in \u001b[0;36m_kmeans_single_lloyd\u001b[1;34m(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)\u001b[0m\n\u001b[0;32m    675\u001b[0m strict_convergence \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    677\u001b[0m \u001b[39m# Threadpoolctl context to limit the number of threads in second level of\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[39m# nested parallelism (i.e. BLAS) to avoid oversubscription.\u001b[39;00m\n\u001b[1;32m--> 679\u001b[0m \u001b[39mwith\u001b[39;00m threadpool_limits(limits\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, user_api\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mblas\u001b[39;49m\u001b[39m\"\u001b[39;49m):\n\u001b[0;32m    680\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iter):\n\u001b[0;32m    681\u001b[0m         lloyd_iter(\n\u001b[0;32m    682\u001b[0m             X,\n\u001b[0;32m    683\u001b[0m             sample_weight,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    689\u001b[0m             n_threads,\n\u001b[0;32m    690\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\fixes.py:139\u001b[0m, in \u001b[0;36mthreadpool_limits\u001b[1;34m(limits, user_api)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[39mreturn\u001b[39;00m controller\u001b[39m.\u001b[39mlimit(limits\u001b[39m=\u001b[39mlimits, user_api\u001b[39m=\u001b[39muser_api)\n\u001b[0;32m    138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m threadpoolctl\u001b[39m.\u001b[39;49mthreadpool_limits(limits\u001b[39m=\u001b[39;49mlimits, user_api\u001b[39m=\u001b[39;49muser_api)\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:171\u001b[0m, in \u001b[0;36mthreadpool_limits.__init__\u001b[1;34m(self, limits, user_api)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, limits\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, user_api\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    168\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_limits, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_user_api, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prefixes \u001b[39m=\u001b[39m \\\n\u001b[0;32m    169\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params(limits, user_api)\n\u001b[1;32m--> 171\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_threadpool_limits()\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:268\u001b[0m, in \u001b[0;36mthreadpool_limits._set_threadpool_limits\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_limits \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m modules \u001b[39m=\u001b[39m _ThreadpoolInfo(prefixes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prefixes,\n\u001b[0;32m    269\u001b[0m                           user_api\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_user_api)\n\u001b[0;32m    270\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m    271\u001b[0m     \u001b[39m# self._limits is a dict {key: num_threads} where key is either\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[39m# a prefix or a user_api. If a module matches both, the limit\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[39m# corresponding to the prefix is chosed.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     \u001b[39mif\u001b[39;00m module\u001b[39m.\u001b[39mprefix \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_limits:\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:340\u001b[0m, in \u001b[0;36m_ThreadpoolInfo.__init__\u001b[1;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_api \u001b[39m=\u001b[39m [] \u001b[39mif\u001b[39;00m user_api \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m user_api\n\u001b[0;32m    339\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodules \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 340\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_modules()\n\u001b[0;32m    341\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_if_incompatible_openmp()\n\u001b[0;32m    342\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:373\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._load_modules\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_modules_with_dyld()\n\u001b[0;32m    372\u001b[0m \u001b[39melif\u001b[39;00m sys\u001b[39m.\u001b[39mplatform \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwin32\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 373\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_modules_with_enum_process_module_ex()\n\u001b[0;32m    374\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_modules_with_dl_iterate_phdr()\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:485\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._find_modules_with_enum_process_module_ex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    482\u001b[0m         filepath \u001b[39m=\u001b[39m buf\u001b[39m.\u001b[39mvalue\n\u001b[0;32m    484\u001b[0m         \u001b[39m# Store the module if it is supported and selected\u001b[39;00m\n\u001b[1;32m--> 485\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_module_from_path(filepath)\n\u001b[0;32m    486\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    487\u001b[0m     kernel_32\u001b[39m.\u001b[39mCloseHandle(h_process)\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:515\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._make_module_from_path\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[39mif\u001b[39;00m prefix \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprefixes \u001b[39mor\u001b[39;00m user_api \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_api:\n\u001b[0;32m    514\u001b[0m     module_class \u001b[39m=\u001b[39m \u001b[39mglobals\u001b[39m()[module_class]\n\u001b[1;32m--> 515\u001b[0m     module \u001b[39m=\u001b[39m module_class(filepath, prefix, user_api, internal_api)\n\u001b[0;32m    516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodules\u001b[39m.\u001b[39mappend(module)\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:606\u001b[0m, in \u001b[0;36m_Module.__init__\u001b[1;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minternal_api \u001b[39m=\u001b[39m internal_api\n\u001b[0;32m    605\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dynlib \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mCDLL(filepath, mode\u001b[39m=\u001b[39m_RTLD_NOLOAD)\n\u001b[1;32m--> 606\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mversion \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_version()\n\u001b[0;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_threads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_num_threads()\n\u001b[0;32m    608\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_extra_info()\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:646\u001b[0m, in \u001b[0;36m_OpenBLASModule.get_version\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m get_config \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dynlib, \u001b[39m\"\u001b[39m\u001b[39mopenblas_get_config\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    644\u001b[0m                      \u001b[39mlambda\u001b[39;00m: \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    645\u001b[0m get_config\u001b[39m.\u001b[39mrestype \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_char_p\n\u001b[1;32m--> 646\u001b[0m config \u001b[39m=\u001b[39m get_config()\u001b[39m.\u001b[39;49msplit()\n\u001b[0;32m    647\u001b[0m \u001b[39mif\u001b[39;00m config[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOpenBLAS\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    648\u001b[0m     \u001b[39mreturn\u001b[39;00m config[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "\n",
    "#2 clusters \n",
    "premType_2_Clusters = KMeans(n_clusters=2,random_state=0).fit(premType_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#4 clusters \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m premType_4_Clusters \u001b[39m=\u001b[39m KMeans(n_clusters\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(premType_scaled)\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1468\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1465\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInitialization complete\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1467\u001b[0m \u001b[39m# run a k-means once\u001b[39;00m\n\u001b[1;32m-> 1468\u001b[0m labels, inertia, centers, n_iter_ \u001b[39m=\u001b[39m kmeans_single(\n\u001b[0;32m   1469\u001b[0m     X,\n\u001b[0;32m   1470\u001b[0m     sample_weight,\n\u001b[0;32m   1471\u001b[0m     centers_init,\n\u001b[0;32m   1472\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m   1473\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1474\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tol,\n\u001b[0;32m   1475\u001b[0m     n_threads\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_threads,\n\u001b[0;32m   1476\u001b[0m )\n\u001b[0;32m   1478\u001b[0m \u001b[39m# determine if these results are the best so far\u001b[39;00m\n\u001b[0;32m   1479\u001b[0m \u001b[39m# we chose a new run if it has a better inertia and the clustering is\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \u001b[39m# different from the best so far (it's possible that the inertia is\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m \u001b[39m# slightly better even if the clustering is the same with potentially\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \u001b[39m# permuted labels, due to rounding errors)\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m \u001b[39mif\u001b[39;00m best_inertia \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   1484\u001b[0m     inertia \u001b[39m<\u001b[39m best_inertia\n\u001b[0;32m   1485\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_same_clustering(labels, best_labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_clusters)\n\u001b[0;32m   1486\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:679\u001b[0m, in \u001b[0;36m_kmeans_single_lloyd\u001b[1;34m(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)\u001b[0m\n\u001b[0;32m    675\u001b[0m strict_convergence \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    677\u001b[0m \u001b[39m# Threadpoolctl context to limit the number of threads in second level of\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[39m# nested parallelism (i.e. BLAS) to avoid oversubscription.\u001b[39;00m\n\u001b[1;32m--> 679\u001b[0m \u001b[39mwith\u001b[39;00m threadpool_limits(limits\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, user_api\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mblas\u001b[39;49m\u001b[39m\"\u001b[39;49m):\n\u001b[0;32m    680\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iter):\n\u001b[0;32m    681\u001b[0m         lloyd_iter(\n\u001b[0;32m    682\u001b[0m             X,\n\u001b[0;32m    683\u001b[0m             sample_weight,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    689\u001b[0m             n_threads,\n\u001b[0;32m    690\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\fixes.py:139\u001b[0m, in \u001b[0;36mthreadpool_limits\u001b[1;34m(limits, user_api)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[39mreturn\u001b[39;00m controller\u001b[39m.\u001b[39mlimit(limits\u001b[39m=\u001b[39mlimits, user_api\u001b[39m=\u001b[39muser_api)\n\u001b[0;32m    138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m threadpoolctl\u001b[39m.\u001b[39;49mthreadpool_limits(limits\u001b[39m=\u001b[39;49mlimits, user_api\u001b[39m=\u001b[39;49muser_api)\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:171\u001b[0m, in \u001b[0;36mthreadpool_limits.__init__\u001b[1;34m(self, limits, user_api)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, limits\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, user_api\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    168\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_limits, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_user_api, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prefixes \u001b[39m=\u001b[39m \\\n\u001b[0;32m    169\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params(limits, user_api)\n\u001b[1;32m--> 171\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_threadpool_limits()\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:268\u001b[0m, in \u001b[0;36mthreadpool_limits._set_threadpool_limits\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_limits \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m modules \u001b[39m=\u001b[39m _ThreadpoolInfo(prefixes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prefixes,\n\u001b[0;32m    269\u001b[0m                           user_api\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_user_api)\n\u001b[0;32m    270\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m    271\u001b[0m     \u001b[39m# self._limits is a dict {key: num_threads} where key is either\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[39m# a prefix or a user_api. If a module matches both, the limit\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[39m# corresponding to the prefix is chosed.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     \u001b[39mif\u001b[39;00m module\u001b[39m.\u001b[39mprefix \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_limits:\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:340\u001b[0m, in \u001b[0;36m_ThreadpoolInfo.__init__\u001b[1;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_api \u001b[39m=\u001b[39m [] \u001b[39mif\u001b[39;00m user_api \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m user_api\n\u001b[0;32m    339\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodules \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 340\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_modules()\n\u001b[0;32m    341\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_if_incompatible_openmp()\n\u001b[0;32m    342\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:373\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._load_modules\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_modules_with_dyld()\n\u001b[0;32m    372\u001b[0m \u001b[39melif\u001b[39;00m sys\u001b[39m.\u001b[39mplatform \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwin32\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 373\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_modules_with_enum_process_module_ex()\n\u001b[0;32m    374\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_modules_with_dl_iterate_phdr()\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:485\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._find_modules_with_enum_process_module_ex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    482\u001b[0m         filepath \u001b[39m=\u001b[39m buf\u001b[39m.\u001b[39mvalue\n\u001b[0;32m    484\u001b[0m         \u001b[39m# Store the module if it is supported and selected\u001b[39;00m\n\u001b[1;32m--> 485\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_module_from_path(filepath)\n\u001b[0;32m    486\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    487\u001b[0m     kernel_32\u001b[39m.\u001b[39mCloseHandle(h_process)\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:515\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._make_module_from_path\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[39mif\u001b[39;00m prefix \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprefixes \u001b[39mor\u001b[39;00m user_api \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_api:\n\u001b[0;32m    514\u001b[0m     module_class \u001b[39m=\u001b[39m \u001b[39mglobals\u001b[39m()[module_class]\n\u001b[1;32m--> 515\u001b[0m     module \u001b[39m=\u001b[39m module_class(filepath, prefix, user_api, internal_api)\n\u001b[0;32m    516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodules\u001b[39m.\u001b[39mappend(module)\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:606\u001b[0m, in \u001b[0;36m_Module.__init__\u001b[1;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minternal_api \u001b[39m=\u001b[39m internal_api\n\u001b[0;32m    605\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dynlib \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mCDLL(filepath, mode\u001b[39m=\u001b[39m_RTLD_NOLOAD)\n\u001b[1;32m--> 606\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mversion \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_version()\n\u001b[0;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_threads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_num_threads()\n\u001b[0;32m    608\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_extra_info()\n",
      "File \u001b[1;32mc:\\Users\\JBarr\\anaconda3\\envs\\myenv\\lib\\site-packages\\threadpoolctl.py:646\u001b[0m, in \u001b[0;36m_OpenBLASModule.get_version\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m get_config \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dynlib, \u001b[39m\"\u001b[39m\u001b[39mopenblas_get_config\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    644\u001b[0m                      \u001b[39mlambda\u001b[39;00m: \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    645\u001b[0m get_config\u001b[39m.\u001b[39mrestype \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_char_p\n\u001b[1;32m--> 646\u001b[0m config \u001b[39m=\u001b[39m get_config()\u001b[39m.\u001b[39;49msplit()\n\u001b[0;32m    647\u001b[0m \u001b[39mif\u001b[39;00m config[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOpenBLAS\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    648\u001b[0m     \u001b[39mreturn\u001b[39;00m config[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "\n",
    "#4 clusters \n",
    "premType_4_Clusters = KMeans(n_clusters=4,random_state=0).fit(premType_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#calculate the Silhouette score for each cluster \n",
    "#this score ranges from âˆ’1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.\n",
    "\n",
    "# premType_2_Clusters_silhouette_avg = silhouette_score(premType_scaled, premType_2_Clusters.labels_)\n",
    "# print('Silhouette score:', premType_2_Clusters_silhouette_avg )\n",
    "# #score 0.930\n",
    "\n",
    "# premType_4_Clusters_silhouette_avg = silhouette_score(premType_scaled, premType_4_Clusters.labels_)\n",
    "# print('Silhouette score:', premType_4_Clusters_silhouette_avg )\n",
    "# #score 0.944\n",
    "\n",
    "#cluster membership\n",
    "membership = pd.Series(premType_4_Clusters.labels_, index = moneyFlow.index)\n",
    "moneyFlow['membership'] = membership\n",
    "moneyFlow.head()\n",
    "moneyFlow[\"membership\"].unique()\n",
    "\n",
    "\n",
    "#-------------------------Dataset Based on Clustering -------------------------#\n",
    "#create four data sets according to membership \n",
    "moneyFlow_cluster_1 = moneyFlow[moneyFlow[\"membership\"] == 0]\n",
    "moneyFlow_cluster_2 = moneyFlow[moneyFlow[\"membership\"] == 1]\n",
    "moneyFlow_cluster_3 = moneyFlow[moneyFlow[\"membership\"] == 2]\n",
    "moneyFlow_cluster_4 = moneyFlow[moneyFlow[\"membership\"] == 3]\n",
    "\n",
    "#-------------------------Data Split-------------------------#\n",
    "# Split the data into X and y for cluster 1\n",
    "X_cluster_1 = moneyFlow_cluster_1.drop('Sentiment', axis=1)\n",
    "y_cluster_1= moneyFlow_cluster_1['Sentiment']\n",
    "# Split the data into training and testing sets for cluster 1\n",
    "X_train_cluster_1, X_test_cluster_1, y_train_cluster_1, y_test_cluster_1 = train_test_split(X_cluster_1, y_cluster_1, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the data into X and y for cluster 2\n",
    "X_cluster_2 = moneyFlow_cluster_2.drop('Sentiment', axis=1)\n",
    "y_cluster_2= moneyFlow_cluster_2['Sentiment']\n",
    "# Split the data into training and testing sets for cluster 1\n",
    "X_train_cluster_2, X_test_cluster_2, y_train_cluster_2, y_test_cluster_2 = train_test_split(X_cluster_2, y_cluster_2, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the data into X and y for cluster 3\n",
    "X_cluster_3 = moneyFlow_cluster_3.drop('Sentiment', axis=1)\n",
    "y_cluster_3= moneyFlow_cluster_3['Sentiment']\n",
    "# Split the data into training and testing sets for cluster 1\n",
    "X_train_cluster_3, X_test_cluster_3, y_train_cluster_3, y_test_cluster_3 = train_test_split(X_cluster_3, y_cluster_3, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the data into X and y for cluster 4\n",
    "X_cluster_4 = moneyFlow_cluster_4.drop('Sentiment', axis=1)\n",
    "y_cluster_4= moneyFlow_cluster_4['Sentiment']\n",
    "# Split the data into training and testing sets for cluster 1\n",
    "X_train_cluster_4, X_test_cluster_4, y_train_cluster_4, y_test_cluster_4 = train_test_split(X_cluster_4, y_cluster_4, test_size=0.3, random_state=42)\n",
    "\n",
    "#-------------------------Feature Scaling-------------------------#\n",
    "scaler = StandardScaler()\n",
    "X_train_cluster_1 = scaler.fit_transform(X_train_cluster_1)\n",
    "X_test_cluster_1 = scaler.fit_transform(X_test_cluster_1)\n",
    "X_train_cluster_2 = scaler.fit_transform(X_train_cluster_2)\n",
    "X_test_cluster_2= scaler.fit_transform(X_test_cluster_2)\n",
    "X_train_cluster_3 = scaler.fit_transform(X_train_cluster_3)\n",
    "X_test_cluster_3= scaler.fit_transform(X_test_cluster_3)\n",
    "X_train_cluster_4 = scaler.fit_transform(X_train_cluster_4)\n",
    "X_test_cluster_4= scaler.fit_transform(X_test_cluster_4)\n",
    "\n",
    "#-------------------------Logisitc Regression Cluster 1-------------------------#\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "lr.fit(X_train_cluster_1, y_train_cluster_1)\n",
    "lr_pred_cluster_1 = lr.predict(X_test_cluster_1)\n",
    "\n",
    "#-------------------------Logisitc Regression Classification Report and Confusion Matrix for Cluster 1-------------------------#\n",
    "print(\"Logistic Regression classification report:\")\n",
    "print(classification_report(y_test_cluster_1, lr_pred_cluster_1))\n",
    "print(\"Logistic Regression confusion matrix:\")\n",
    "print(confusion_matrix(y_test_cluster_1, lr_pred_cluster_1))\n",
    "\n",
    "\n",
    "#-------------------------Random Forest Cluster 1-------------------------#\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=42)\n",
    "rf.fit(X_train_cluster_1, y_train_cluster_1)\n",
    "rf_pred_cluster_1 = rf.predict(X_test_cluster_1)\n",
    "\n",
    "#-------------------------Random Forest Classification Report and Confusion Matrix for Cluster 1-------------------------#\n",
    "print(\"Random Forest classification report:\")\n",
    "print(classification_report(y_test_cluster_1, rf_pred_cluster_1))\n",
    "print(\"Random Forest confusion matrix:\")\n",
    "print(confusion_matrix(y_test_cluster_1, rf_pred_cluster_1))\n",
    "\n",
    "\n",
    "#-------------------------Neural Netowrk-------------------------#\n",
    "nn = MLPClassifier(hidden_layer_sizes=(64,),max_iter=1000, random_state=42)\n",
    "nn.fit(X_train_cluster_1, y_train_cluster_1)\n",
    "nn_pred_cluster_1= nn.predict(X_test_cluster_1)\n",
    "\n",
    "\n",
    "#-------------------------Neural Network Classification Report and Confusion Matrix-------------------------#\n",
    "print(\"Neural Network classification report:\")\n",
    "print(classification_report(y_test_cluster_1, nn_pred_cluster_1))\n",
    "print(\"Neural Network confusion matrix:\")\n",
    "print(confusion_matrix(y_test_cluster_1, nn_pred_cluster_1))\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------KNN-------------------------#\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_cluster_1, y_train_cluster_1)\n",
    "knn_pred_cluster_1 = knn.predict(X_test_cluster_1)\n",
    "\n",
    "\n",
    "#-------------------------KNN Classification Report and Confusion Matrix-------------------------#\n",
    "print(\"KNN Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_cluster_1, knn_pred_cluster_1))\n",
    "print(\"\\nKNN Classification Report:\")\n",
    "print(classification_report(y_test_cluster_1, knn_pred_cluster_1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
